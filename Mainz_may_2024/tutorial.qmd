---
title: "Multiverse Tutorial"
format: html
editor: visual
---

```{r include = FALSE}
# Load required libraries
library(tidyverse)
library(multitool)
library(lme4)
library(performance)
library(specr)
library(ggsci)

library(patchwork)
```

```{r}
# Load data
data <- read_csv("data.csv") 
  
data
```

# 1. Building the multiverse pipeline

## 1.1. Add filtering decisions

The first step in the multiverse analysis is deciding which data filtering decisions we want to include. We decided including or excluding participants who:

1.  Scored below 0.5 on a build-in bot-detection measure on Prolific (potentially indicating a bot);
2.  Did not enter fullscreen mode prior to starting the tasks;
3.  Exited fullscreen mode at any point during the tasks;
4.  Indicated high levels of noise in their environment (three options: score \< 2, score \< 4, include all);
5.  Indicated that they were interrupted during the experiment.
6.  Indicated that they got up at some point during the experiment.

To add these filtering decisions to our multiverse pipeline, we use the `add_filters()` function of the multitool function. The multiverse pipeline always starts with the raw data. We then build out the pipeline from there by creating a tidyverse-style pipeline.

Run the following code:

```{r}
data |> 
  add_filters(
    bot_detection    > 0.4, # Only keep participants who passed bot detection
    fullscreenenter == 1,   # Only keep participants who entered fullscreen
    fullscreenexit  == 1,   # Only keep participants who stayed in fullscreen
    noise            < 2,   # Only keep participants who reported noise-level of 0 or 1 (on scale of 0-4)
    noise            < 4,   # Only keep participants who reported noise-level of 0-3 (on scale of 0-4)
    interrupted     == 0,   # Only keep participants who were not interrupted
    getup           == 0    # Only keep participants who did not get up during the experiment
  )
```

## 1.3. Add pre-processing steps

Sometimes, we want to include some final pre-processing steps *after* filtering the data but *before* running the model. For example, if we would like to standardize the independent variable, we could do so like this:

```{r}
data |> 
  add_preprocess(process_name = "std", code = "mutate(unp = scale(unp) |> as.numeric())")
```

## 1.4. Add the model

```{r}
data |> 
  add_model(model_desc = "lm", code = lm(shifting ~ unp))
```

## 1.5 Add post-processing

```{r}
data |> 
  add_postprocess(postprocess_name = "skew", "(\\\\(x) residuals(x) |> scale() |> parameters::skewness())()") |>
  add_postprocess(postprocess_name = "kurtosis", "(\\\\(x) residuals(x) |> scale() |> parameters::kurtosis())()")
```

## 1.6. Creating the full multiverse pipeline

Let's combine all of the above in a single multiverse pipeline:

```{r}
full_pipeline01 <- data |> 
  add_filters(
    bot_detection    > 0.4, # Only keep participants who passed bot detection
    fullscreenenter == 1, # Only keep participants who entered fullscreen
    fullscreenexit  == 1, # Only keep participants who stayed in fullscreen
    noise            < 2, # Only keep participants who reported noise-level of 0 or 1 (on scale of 0-4)
    noise            < 4,
    interrupted      == 0,  # Only keep participants who were not interrupted
    getup            == 0
  ) |> 
  add_preprocess(process_name = "std", code = "mutate(unp = scale(unp) |> as.numeric())") |> 
  add_model(model_desc = "lm", code = lm(shifting ~ unp)) |> 
  add_postprocess(postprocess_name = "skew", "(\\\\(x) residuals(x) |> scale() |> parameters::skewness())()") |>
  add_postprocess(postprocess_name = "kurtosis", "(\\\\(x) residuals(x) |> scale() |> parameters::kurtosis())()")

full_pipeline01
```

# 2. Checking our pipeline for potential mistakes

**See https://ethan-young.github.io/multitool/articles/validate-your-blueprint.html for more examples**

Making a multiverse pipeline is straightforward, but it is easy to make mistakes. One thing that is important to check is how many participants are excluded under particular filtering decisions:

```{r}
summarize_filter_ns(full_pipeline01)
```

**EXERCISE 1:** Fix my mistake (and optionally, unnecessary decisions) in the multiverse pipeline.

It is also possible to assess the size of our multiverse pipeline. For example, we can see..

The total number of distinct analysis pipelines:

```{r}
detect_multiverse_n(full_pipeline01)
```

The number of unique filtering decisions:

```{r}
detect_n_filters(full_pipeline01)
```

# 3. Expanding the pipeline specification

Once we are satisfied with our pipeline specification, we can expand it and test it further. To do so, expand into a full decision grid:

```{r}
expanded_pipeline01 <- expand_decisions(full_pipeline01)

expanded_pipeline01
```

The full, expanded decision grid has a special feature: it stores the code for each individual analysis pipeline in the multiverse. This means that it is very easy to check the code that is used to generate a specific analysis pipeline in our multiverse.

For example, we can look at the code that takes care of the data filtering in the first analysis pipeline:

```{r}
show_code_filter(expanded_pipeline01, decision_num = 1)
```

We can also look at the code that runs the model in the 12th analysis pipeline:

```{r}
show_code_model(expanded_pipeline01, decision_num = 12, copy = TRUE)
```

Setting the `copy` argument to TRUE sends the code straight to your clipboard. This is nice for debugging if the multiverse analysis throws an error and you want to understand better what's going wrong.

# 4. Running the multiverse analysis.

Once we're confident that we correctly specified the multiverse pipeline, it's time to actually run the multiverse analysis!

```{r}
multiverse_results01 <- run_multiverse(expanded_pipeline01)
```

The time it takes to run the multiverse analysis depends on the number of analysis pipelines in the multiverse and the complexity of the model(s). In our relatively simple example, it should not take more than 2-3 minutes.

The resulting tibble consists of one line per analysis pipeline (indexed with the `decision` variable). The results are nested in list columns:

```{r}
multiverse_results01
```

# 5. Unpacking the multiverse results

```{r}
mod_summary01 <- reveal_model_parameters(multiverse_results01, .unpack_specs = "wide")

mod_summary01
```

**EXERCISE 2:** Unpack the skewness and kurtosis statistics using `multitool::reveal()` (once for skewness and once for kurtosis). Use the `.what` and `.which` arguments to dig into the correct columns.

```{r}
# Unpack skewness
multitool::reveal(multiverse_results01, .what = 'skew_fitted', .which = 'skew_full')

# Unpack kurtosis


```

Using `condense`, we can summarise specific results. Let's start by summarizing the regression coefficients.

```{r}
mod_coef01 <- mod_summary01 |> 
  filter(parameter == "unp") |>
  condense(.what = coefficient, .how = list(median = median))

mod_coef01
```

Now let's calculate the proportion of p-values that were significant across the entire multiverse, grouped by IV:

```{r}
mod_p <- mod_summary01 |> 
  filter(parameter == "unp") |>
  condense(.what = p, .how = ~sum(.x < .05)/n())

mod_p
```

# 6. Visualizing the multiverse

Besides knowing the overall effects, we would want to know which decisions tend to influence our estimates a lot. The best way to do this is to visualize our results. Unfortunately, `multitool` does not contain plotting functions as of yet, so we'll have to do some manual coding.

```{r}
## General ggplot theme for plots
theme_set(
  theme_bw() +
    theme(
      axis.line.y       = element_line(linewidth = 1),
      axis.line.x       = element_line(linewidth = 1),
      axis.text.y       = element_text(size = 14),
      axis.text.x       = element_text(size = 14),
      axis.title.y      = element_text(size = rel(1), margin = margin(1,0,0,0,"lines")),
      axis.ticks.y      = element_blank(),
      axis.ticks.x      = element_blank(),
      
      panel.border      = element_blank(), 
      panel.spacing.y   = unit(0.5, "lines"),
      plot.margin       = margin(.25,.25,.25,.25,"lines"),
      plot.background   = element_rect(color = NA),
      plot.title        = element_text(size = 14, hjust = 0, margin = margin(0,0,.5,0, "lines")),
      plot.subtitle     = element_blank(),
      panel.grid        = element_line(color = NA),
      strip.background  = element_blank(), 
      strip.placement   = "outside",
      strip.text        = element_text(size = rel(.85), angle = 0),
      legend.background = element_rect(fill='transparent'), #
      legend.box.background = element_rect(color = 'transparent', fill='transparent'),
    )
)

pval_colors <- c("sig" = "#006D77", "non-sig" = "gray70")
```

There are several types of plots that we can create to visualize the multiverse.

## 6.1. Effect Curve Plot

```{r}
curve_plot <- mod_summary01 |>
  filter(parameter == "unp") |> 
  arrange(coefficient) |> # Arrange coefficients from smallest to largest
  mutate(
    p_sig = ifelse(p < .05, "sig", "non-sig"),  # Significant yes or no? Used for coloring the points 
    order = 1:n()                               # Values for the x-axis
  ) |> 
  ggplot(aes(order, coefficient, color = p_sig)) + 
  # Add a ribbon that shows the 95% confidence intervals
  geom_ribbon(
    aes(ymin = ci_low, ymax = ci_high, x = order),
    fill = "gray90",
    inherit.aes = F,
    show.legend = F
  ) +
  geom_point(size = 3, shape = 19, show.legend = F) + 
  geom_hline(aes(yintercept = 0), size = .5, linetype = "solid") +
  geom_point( # Add a single point showing the median estimate
    data = mod_coef01, # Using the summarized median coefficients we created above
    aes(x = 48, y = coefficient_median),
    shape = 1,
    size = 3,
    fill = "white",
    stroke = 3,
    show.legend = F,
    inherit.aes = F
    ) +
  geom_text( # Add the median coefficient in text
        data = mod_coef01,
        aes(y = coefficient_median, label = paste0("\u03b2\ = ", as.character(round(coefficient_median,2))), x = 48),
        nudge_y = -.01,
        size = 3,
        show.legend = F,
        inherit.aes = F
      ) +
  geom_text( # Add text showing the proportion of significant p-values
    data = mod_p,
        aes(x = 48, y = 0.1, label = paste0(round(p_1, 2)*100, "% of p-values < .05")),
        size = 3,
        show.legend = F,
        inherit.aes = F
      ) +
  xlim(0,105) +
    scale_color_manual(values = pval_colors) +
      labs(
        y = "Coefficient (standardized)\n",
        x = ""
      ) +
      theme(
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.line.x = element_blank()
      )

curve_plot
```

## 6.2. P-distribution plot

```{r}
p_plot <- mod_summary01 |> 
  ggplot(aes(p)) +
  geom_histogram(color = "black", size = .2, bins = 100) +
  geom_vline(aes(xintercept = .05), linetype = "dashed") + # Add a line indicationg p = .05
  geom_text( # Add text showing the proportion of significant p-values
    data = mod_p,
    aes(x = 0.2, y = 50, label = paste0(round(p_1, 1)*100, "% of p-values < .05")),
    size = 3,
    show.legend = F,
    inherit.aes = F
  ) +
  scale_x_continuous(breaks = seq(0, 1, 0.1)) +
  scale_y_continuous("Freq\n") 

p_plot
```

## 6.3. Portion of explained variance of each decision

```{r}
var_fit <- mod_summary01 |> 
  filter(parameter == "unp") |> 
  lmer(data = _, coefficient ~ 1 + (1|bot_detection) + (1|fullscreenenter) + (1|fullscreenexit) + (1|noise) + (1|interrupted) + (1|getup))

var_model <- specr::icc_specs(var_fit) |> 
  as_tibble() |> 
  mutate(iv = "unp")


var_plot <- var_model |> 
      ggplot(aes(grp, percent, fill = grp)) +
      geom_bar(stat = "identity") +
      scale_fill_uchicago() +
      coord_flip() +
      guides(fill = 'none') +
      labs(
        x = "",
        y = "Explained variance in estimate (%)"
      )

var_plot
```

## 6.4 Digging into the filtering specifications

```{r}
long_specs01 <- reveal_model_parameters(multiverse_results01, .unpack_specs = "long") |> 
  filter(parameter == "unp") |> 
  arrange(coefficient) |> # Arrange coefficients from smallest to largest
  select(decision, decision_set, alternatives, p) |> 
  filter(decision_set != "model") |> 
  distinct() |> 
  mutate(
    p_sig = ifelse(p < .05, "sig", "non-sig"),
    spec_rank = rep(1:96, each = 6)
    ) |>   # Significant yes or no? Used for coloring the points 
  select(decision, decision_set, alternatives, spec_rank, p, p_sig)

spec_plot <- long_specs01 |> 
  ggplot(aes(x = spec_rank, y = alternatives, color = p_sig)) +
  geom_point(size = 4, shape = 73, show.legend = F) +
  geom_text(
    data = long_specs01 %>% 
      group_by(decision_set, alternatives) %>% 
      summarize(
        n_sig    = sum(p < .05),
        prop_sig = (sum(p < .05)/n()),
        prop_sig = ifelse(prop_sig %in% c(0,1), NA, round(prop_sig,2) %>% paste0() %>% str_remove("^0")),
      ) %>% ungroup(),
    aes(x = 100, y = alternatives, label = prop_sig), 
    size = 3, 
    nudge_x = 4,
    show.legend = F,
    inherit.aes = F
  ) +
  geom_vline(aes(xintercept = 100), show.legend = F) +
  scale_x_continuous("") +
  scale_y_discrete() +
  scale_color_manual(values = pval_colors) +
  ggtitle("Specifications") +
  theme(
    strip.text      = element_blank(),
    panel.spacing.y = unit(0.1,"lines"), 
    axis.text.y     = element_text(angle = 0, hjust = 1, vjust = .5, size = rel(.95)),
    axis.title.y    = element_blank(),
    axis.line.x     = element_line(),
    axis.text.x     = element_blank(),
    axis.ticks.x    = element_blank()
  )

spec_plot
```

## 6.5 Combining all plots using `patchwork`

```{r}
#| fig-height: 20
#| fig.width: 10
(curve_plot + spec_plot) + plot_layout(ncol = 1) 
```

# Epilogue: Looping over variables

```{r}
data02 <- read_csv('data02.csv')

data02
```

When we loop over different variables, we can use `glue` syntax ({}) to refer to the variable. Below, we use "{iv}" as a placeholder to refer to the IV, which `multitool` will then automatically replace with the correct IV.

```{r}
full_pipeline02 <- data02 |> 
  add_variables(var_group = "iv", matches("^unp")) |>
 # add_variables(var_group = "dv", shift1, shift2) |> 
  add_preprocess(process_name = "std", "mutate({iv} = scale({iv}) |> as.numeric())") |> 
  add_model(model_desc = "lm", lm({dv} ~ {iv}))

```
